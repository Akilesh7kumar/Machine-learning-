{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing model's accuracy with sklearn model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Logistic regression\n",
    "class Logitregression():\n",
    "    def __init__(self,learning_rate,iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        \n",
    "      #Function for model training\n",
    "    def fit(self,X,Y):\n",
    "        #no of training examples, no of features\n",
    "        self.m,self.n=X.shape\n",
    "        #weight initialization\n",
    "        self.W=np.zeros(self.n)\n",
    "        self.b=0\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        \n",
    "        #gradient descent learning\n",
    "        for i in range(self.iterations):\n",
    "            self.update_weights()\n",
    "        return self   \n",
    "    #Helper functions to update weight in gradient descents\n",
    "    def update_weights(self):\n",
    "        A=1/(1+np.exp(-(self.X.dot(self.W)+self.b)))\n",
    "        #calculate gradients\n",
    "        tmp=( A -self.Y.T)\n",
    "        tmp = np.reshape(tmp,self.m)\n",
    "        dw=np.dot(self.X.T,tmp)/self.m\n",
    "        db=np.sum(tmp)/self.m\n",
    "        #update weigths\n",
    "        self.W= self.W -self .learning_rate * dw\n",
    "        self.b= self.b -self .learning_rate * db\n",
    "        \n",
    "        return self\n",
    "    #HYpothetical function h(x)\n",
    "    def predict(self,X):\n",
    "       Z = 1/(1 + np.exp( -(X.dot(self.W) + self.b) ) )\n",
    "       Y =np.where(Z<0.5,1,0) \n",
    "       return Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test by our model: 47.22222222222222\n",
      "Accuracy on test by the sklearn model: 72.22222222222221\n"
     ]
    }
   ],
   "source": [
    "#importing dataset\n",
    "df=pd.read_csv(\"diabetes.csv\")\n",
    "X=df.iloc[:,:-1].values\n",
    "Y=df.iloc[:,-1:].values\n",
    "\n",
    "X_train ,X_test,Y_train, Y_test = train_test_split(X,Y,test_size = 1/3,random_state=4)\n",
    "\n",
    "#model training\n",
    "model = Logitregression (learning_rate = 0.01, iterations = 1000)\n",
    "\n",
    "model.fit(X_train,Y_train)\n",
    "model1=LogisticRegression()\n",
    "model1.fit(X_train,Y_train)\n",
    "\n",
    "#prediction on test set\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred1 = model1.predict(X_test)\n",
    "# preformance measure\n",
    "correctly_classified = 0\n",
    "correctly_classified1 = 0\n",
    "\n",
    "#counter\n",
    "\n",
    "count = 0\n",
    "for count in range(np.size(Y_pred)):\n",
    "    if Y_test[count] == Y_pred[count]:\n",
    "        correctly_classified =correctly_classified +1\n",
    "    if Y_test[count] == Y_pred1[count]:\n",
    "        correctly_classified1 =correctly_classified1 +1    \n",
    "        \n",
    "    count=count+1\n",
    "    \n",
    "print(\"Accuracy on test by our model:\",(correctly_classified / count)*100)\n",
    "print(\"Accuracy on test by the sklearn model:\",(correctly_classified1 / count)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,Y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : [[17  4]\n",
      " [15  0]]\n",
      "Accuracy score  0.4722222222222222\n",
      "Classification report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.81      0.64        21\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.47        36\n",
      "   macro avg       0.27      0.40      0.32        36\n",
      "weighted avg       0.31      0.47      0.37        36\n",
      "\n",
      "Log loss score  18.22888749702844\n",
      "AUc roc curve  0.40476190476190477\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(Y_test,Y_pred)\n",
    "print(\"Confusion matrix :\",conf_matrix)\n",
    "print('Accuracy score ',accuracy_score(Y_test,Y_pred))\n",
    "print('Classification report ',classification_report(Y_test,Y_pred))\n",
    "print('Log loss score ',log_loss(Y_test,Y_pred))\n",
    "print('AUc roc curve ',roc_auc_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
